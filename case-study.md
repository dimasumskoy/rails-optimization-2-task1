# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
Экспериментальным путем выяснил, что более-менее приемлемое время выполнения скрипта получается на объеме данных в 20_000 строк, что и взял за основу для дальнейшего профилирования.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы, я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за в среднем 0,77s на 20_000 строк в выключенным GC, и за 1,18s с включенным.
Изначальные показатели времени с тем же объемом данных были в среднем 13s.

Вот как я построил `feedback_loop`:
1. Написал performance-benchmark скрипт, который измерял время выполнения скрипта на объеме 20_000 строк.
2. Написал performance-тест, который позволял отследить, что после изменений кода время его выполнение не превышало максимального порога, полученного при первых прогонах скрипта.
3. Использовал профилировщики для нахождения главной точки роста.
4. Исправлял код в соответствии с полученной информации о точке роста.
5. Проверял код тестами чтобы убедиться, что нет регресси и код работает исправно.
6. Когда одна точка роста пропадала или переставала быть самой "тяжелой", с помощью профилировщиков находил другую.
7. Go to 4

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался такими инструментами:
1. rbspy для первоначального мониторинга выполнения скрипта
2. ruby-prof в режиме flat для беглого отслеживания главной точки роста
3. ruby-prof в режиме callgrind для детального исследования вызываемых функций главной точкой роста
4. benchmark для отслеживания времени выполнения кода после внесенных изменений

Вот какие проблемы удалось найти и решить

### Ваша находка №1
Выборка сессий юзера с помощью метода #select оказалась самой первой и самой ресурсозатратной точкой роста, которую было несложно обнаружить.
После оптимизации время выполнения сократилось в ~6 раз, и данная точка роста вообще исчезла из результатов профайлеров.

### Ваша находка №2
Дальнейший рефакторинг парсинга юзеров сократил выполнение еще на одну секунду.

### Ваша находка №3
Довольно затратным оказалась выборка уникальных браузеров `uniqueBrowsers` с помощью метода `#all?`
Изменение структуры на Set и использование метода `#include?` дали прирост скорости в 0,1s.

### Ваша находка №4
Даже без профилировщиков было понятно, что использование метода `#split` в нескольких местах для выполнения одних и тех же действий (парсинга юзеров и сессий) излишне затратное. Рефакторинг кода и использование метода всего один раз дало прирост почти в 0,3s.

### Ваша находка №5
Метод `#collect_stats_from_users` вызывался несколько раз, и каждый раз в нем перебирались все пользователи для формирования статистики. Решением было перебор списка юзеров всего один раз, и формирование полной статистики внутри итерации.

### Ваша находка №6
Многократное использование метода `#map` для формирования статистики юзера оказалось тоже довольно затратным. Решением было сокращение и рефакторинг кода, запись общих результатов в переменные.

### Ваша находка №7
Зачем-то использовался `Date.parse`, который парсил дату, а потом методом `#iso8601` дата преобразовывалась в первоначальный вид. Оптимизация этой "мелочи" дала довольно внушительные 0,1s прироста скорости.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы на объеме данных в 20_000 строк с 13s до 0,77s, и с бесконечного времени до 27s (40s с включенным GC) на полном объеме данных, и уложиться в заданный бюджет.

Так же удалось значительно сократить код, сделать его более читаемым и понятным.
Использование класса Work в скрипте сделало код более гибким и масштабируемым.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был написан performance-тест с использованием `rspec-benchmark`, который позволяет убедиться, что код выполняется в заданный порог времени, полученный после оптимизации.
